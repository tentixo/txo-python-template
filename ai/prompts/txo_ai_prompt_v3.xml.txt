<?xml version="1.0" encoding="UTF-8"?>
<txo_python_template version="3.0">
  <metadata>
    <purpose>Guide AI assistants to generate production-ready code following Tentixo patterns</purpose>
    <last_updated>2025-01-15</last_updated>
    <python_version>3.13+</python_version>
  </metadata>

  <ai_behavior>
    <instruction priority="critical">
      When a coder asks for help, FIRST ask clarifying questions:
      - What API/service are you integrating with?
      - What's the input data source and format?
      - What's the expected output?
      - Do you need authentication? What type?
      - Will this run once or on a schedule?
      - Any specific error scenarios to handle?
    </instruction>
    
    <instruction priority="high">
      Challenge vague requirements:
      - "Process data" → What specific transformations?
      - "Call API" → Which endpoints? What data?
      - "Generate report" → What format? What metrics?
    </instruction>
    
    <instruction priority="high">
      NEVER use print(), always use logger
      NEVER construct paths manually, use get_path()
      NEVER pass individual params, pass config dict
      ALWAYS include type hints and docstrings
      ALWAYS use HelpfulError for user-facing errors
    </instruction>
  </ai_behavior>

  <critical_patterns>
    <pattern name="script_structure">
      # src/script_name.py  ← Path comment ALWAYS first line
      """Docstring with purpose and usage."""
      
      from typing import Dict, Any  # Type hints always
      from datetime import datetime, timezone
      
      from utils.logger import setup_logger
      from utils.script_runner import parse_args_and_load_config
      from utils.load_n_save import TxoDataHandler
      from utils.exceptions import HelpfulError
      
      logger = setup_logger()  # Logger before any code
      data_handler = TxoDataHandler()
      
      def main():
          config = parse_args_and_load_config("Description")
          # config automatically has: _org_id, _env_type, _token
    </pattern>
    
    <pattern name="error_handling">
      Use HelpfulError for clear user guidance:
      
      raise HelpfulError(
          what_went_wrong="Configuration file 'x.json' not found",
          how_to_fix="Create the file in config/ directory",
          example="See config/example.json for format"
      )
    </pattern>
    
    <pattern name="config_access">
      # Required config - will raise KeyError if missing
      api_url = config['global']['api-url']  # Hard fail
      
      # Optional config - returns None if missing  
      timeout = config.get('timeouts', {}).get('default', 30)  # Soft fail
    </pattern>
  </critical_patterns>

  <helper_modules>
    <module name="utils.script_runner">
      <function>
        parse_args_and_load_config(description: str, require_token=True, validate_config=True)
        → Returns config dict with _org_id, _env_type, _token injected
        → Handles all initialization, validation, error messages
      </function>
      <function>
        parse_args_and_load_config_extended(description, extra_args)
        → For scripts needing additional command-line arguments
        → extra_args is list of (name, type, help) tuples
      </function>
      <function>
        script_context(description) → Context manager for script execution
      </function>
    </module>

    <module name="utils.logger">
      <function>
        setup_logger(org_id=None) → Returns configured TxoLogger instance
        → Logs INFO to console, DEBUG to file
        → Automatically redacts tokens/secrets
        → Thread-safe singleton
      </function>
      <note>NEVER use print(), always use logger.info/debug/error</note>
    </module>

    <module name="utils.load_n_save">
      <class name="TxoDataHandler">
        <method>load_json(directory, filename) → Dict/List</method>
        <method>load_excel(directory, filename, sheet_name=0) → DataFrame</method>
        <method>load_csv(directory, filename) → DataFrame</method>
        <method>save(data, directory, filename) → Path</method>
        <method>save_gzip(data, directory, filename) → Path</method>
        <method>exists(directory, filename) → bool</method>
        <method>delete(directory, filename) → bool</method>
      </class>
      <note>Handles all file I/O with proper error handling</note>
    </module>

    <module name="utils.api_factory">
      <function>
        create_rest_api(config) → MinimalRestAPI
        → Includes retry logic, rate limiting, circuit breaker
        → Handles 202 Accepted async operations
      </function>
      <function>
        clear_api_cache() → Clears cached API instances
      </function>
      <class name="ApiManager">
        Context manager for API lifecycle
      </class>
    </module>

    <module name="utils.rest_api_helpers">
      <class name="MinimalRestAPI">
        <method>get(url, params=None) → Dict</method>
        <method>post(url, json_data=None) → Dict</method>
        <method>patch(url, json_data=None, etag=None) → Dict</method>
        <method>delete(url, etag=None) → None</method>
        <method>get_odata_entities(base_url, entity_name, odata_filter=None) → List[Dict]</method>
        <method>create_or_update(url, entity_name, key_field, key_value, payload) → RestOperationResult</method>
      </class>
      <note>Automatic retry, pagination, async operation handling</note>
    </module>

    <module name="utils.exceptions">
      <class>HelpfulError(what_went_wrong, how_to_fix, example=None)</class>
      <class>ApiOperationError</class>
      <class>ApiTimeoutError</class>
      <class>ApiAuthenticationError</class>
      <class>ApiValidationError</class>
      <class>EntityNotFoundError</class>
      <class>ConfigurationError</class>
      <class>ValidationError</class>
      <class>FileOperationError</class>
    </module>

    <module name="utils.path_helpers">
      <function>
        get_path(category, filename, ensure_parent=True) → Path
        Categories: 'config', 'data', 'output', 'logs', 'schemas', 'tmp'
      </function>
      <function>get_project_root() → Path</function>
      <function>cleanup_old_files(category, days=30, pattern="*") → List[Path]</function>
      <function>list_files(category, pattern="*", recursive=False) → List[Path]</function>
    </module>

    <module name="utils.config_loader">
      <class name="ConfigLoader">
        <method>load_config(validate=True) → Dict</method>
        <method>load_vat_config(validate=True) → Dict</method>
        <method>get_config_value(key, default=None) → Any</method>
      </class>
      <note>Thread-safe, validates against JSON schemas, caches results</note>
    </module>

    <module name="utils.oauth_helpers">
      <class name="OAuthClient">
        <method>get_client_credentials_token(client_id, client_secret, scope, tenant_id) → str</method>
        <method>get_token_with_refresh(refresh_token, ...) → Tuple[str, str]</method>
      </class>
      <note>Automatic token caching and refresh</note>
    </module>

    <module name="utils.url_helpers">
      <function>build_url(base_url, *path_segments, query_params=None) → str</function>
      <function>build_odata_filter(conditions: Dict) → str</function>
      <function>add_query_params(url, params) → str</function>
      <function>build_context_string(*components) → str (for logging)</function>
    </module>

    <module name="utils.concurrency">
      <function>
        parallel_map(func, items, show_progress=True, max_workers=None) → ProcessingResult
      </function>
      <function>
        batch_process(func, items, batch_size=100) → ProcessingResult
      </function>
      <function>
        rate_limited_parallel(func, items, calls_per_second=10) → ProcessingResult
      </function>
      <class name="ProcessingResult">
        <attr>successful: List[T]</attr>
        <attr>failed: List[Tuple[Any, Exception]]</attr>
        <attr>success_rate: float</attr>
      </class>
    </module>

    <module name="utils.api_common">
      <class>RateLimiter(calls_per_second=10)</class>
      <class>CircuitBreaker(failure_threshold=5, timeout=60)</class>
      <function>apply_jitter(delay, config) → float</function>
      <function>manual_retry(func, max_retries=3, backoff=2.0)</function>
    </module>
  </helper_modules>

  <configuration>
    <file pattern="{org_id}-{env_type}-config.json">
      Main configuration file in config/ directory
      Validated against schemas/org-env-config-schema.json
    </file>
    <file pattern="{org_id}-{env_type}-config-secrets.json">
      Secrets file (gitignored) containing:
      - client-secret: OAuth client secret
      - az-token: Fallback bearer token
    </file>
    <structure>
      {
        "global": {
          "api-base-url": "https://...",
          "tenant-id": "...",
          "client-id": "...",
          "oauth-scope": "..."
        },
        "script-behavior": {
          "api-delay-seconds": 1,
          "enable-rate-limiting": true,
          "rate-limit-per-second": 10,
          "api-timeouts": {
            "rest-timeout-seconds": 60,
            "max-retries": 3
          }
        }
      }
    </structure>
  </configuration>

  <output_patterns>
    <pattern name="file_naming">
      UTC timestamp: datetime.now(timezone.utc).strftime("%Y-%m-%dT%H%MZ")
      Filename: f"{config['_org_id']}-{config['_env_type']}-{purpose}_{utc}.{ext}"
      Example: txo-prod-report_2025-01-15T1430Z.xlsx
    </pattern>
    <pattern name="save_location">
      Always save to 'output' directory:
      data_handler.save(data, "output", filename)
    </pattern>
  </output_patterns>

  <code_quality>
    <rule>Every function needs type hints and docstring</rule>
    <rule>Use logger for all output, never print()</rule>
    <rule>Handle errors with try/except and specific exceptions</rule>
    <rule>Validate config keys exist before accessing</rule>
    <rule>Use HelpfulError for user-facing errors</rule>
    <rule>Pass entire config dict to functions</rule>
    <rule>Use path_helpers for all file paths</rule>
  </code_quality>

  <packages>
    <required>
      requests: HTTP client
      pandas: Data manipulation (lazy loaded)
      openpyxl: Excel file support
      python-dotenv: Environment variables
      pydantic: Data validation
    </required>
    <optional>
      jsonschema: Config validation
      zeep: SOAP client
      tqdm: Progress bars
      tenacity: Advanced retry logic
    </optional>
    <avoid>
      urllib: Use requests instead
      os.path: Use pathlib/path_helpers
      print: Use logger instead
    </avoid>
  </packages>

  <example_script>
    # src/fetch_and_transform.py
    """
    Fetch data from API and transform to Excel.
    
    Usage:
        python fetch_and_transform.py <org_id> <env_type>
    """
    from datetime import datetime, timezone
    from typing import Dict, Any, List
    
    from utils.logger import setup_logger
    from utils.script_runner import parse_args_and_load_config
    from utils.load_n_save import TxoDataHandler
    from utils.api_factory import create_rest_api
    from utils.exceptions import ApiOperationError, HelpfulError
    
    logger = setup_logger()
    data_handler = TxoDataHandler()
    
    def fetch_data(config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Fetch data from API endpoint."""
        api = create_rest_api(config)
        
        try:
            endpoint = config['endpoints']['data_source']
            response = api.get(endpoint)
            return response.get('items', [])
        except KeyError:
            raise HelpfulError(
                what_went_wrong="Missing 'endpoints.data_source' in config",
                how_to_fix="Add endpoints section to your config file",
                example='{"endpoints": {"data_source": "https://api.example.com/data"}}'
            )
        except ApiOperationError as e:
            logger.error(f"API call failed: {e}")
            raise
    
    def transform_data(data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Transform data to desired format."""
        transformed = []
        for item in data:
            transformed.append({
                'id': item.get('id'),
                'name': item.get('name', 'Unknown'),
                'value': item.get('value', 0),
                'processed_at': datetime.now(timezone.utc).isoformat()
            })
        return transformed
    
    def main():
        """Main entry point."""
        config = parse_args_and_load_config("Fetch and transform data")
        
        org_id = config['_org_id']
        env_type = config['_env_type']
        
        logger.info(f"Starting process for {org_id}-{env_type}")
        
        try:
            # Fetch
            logger.info("Fetching data from API...")
            raw_data = fetch_data(config)
            logger.info(f"Fetched {len(raw_data)} records")
            
            # Transform
            logger.info("Transforming data...")
            transformed = transform_data(raw_data)
            
            # Save
            utc = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H%MZ")
            filename = f"{org_id}-{env_type}-transformed_{utc}.json"
            
            output_path = data_handler.save(transformed, "output", filename)
            logger.info(f"Saved to: {output_path}")
            
            logger.info("✅ Process completed successfully")
            
        except HelpfulError:
            raise  # Let script_runner handle display
        except Exception as e:
            logger.error(f"Process failed: {e}", exc_info=True)
            raise HelpfulError(
                what_went_wrong=f"Unexpected error: {e}",
                how_to_fix="Check the logs for details",
                example="Run with --debug for more information"
            )
    
    if __name__ == "__main__":
        main()
  </example_script>
</txo_python_template>