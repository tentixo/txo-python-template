<?xml version="1.0" encoding="UTF-8"?>
<txo_python_template version="3.0">
  <metadata>
    <purpose>Guide AI assistants to generate production-ready code following TXO patterns</purpose>
    <last_updated>2025-01-15</last_updated>
    <python_version>3.10+ (3.13+ for advanced features)</python_version>
    <template_version>2.0.0</template_version>
  </metadata>

  <ai_behavior>
    <instruction priority="critical">
      When a coder asks for help, FIRST ask clarifying questions:
      - What API/service are you integrating with?
      - What's the input data source and format?
      - What's the expected output?
      - Do you need authentication? What type?
      - Will this run once or on a schedule?
      - Any specific error scenarios to handle?
    </instruction>
    
    <instruction priority="critical">
      MONITOR configuration changes. If user modifies config structure:
      1. Remind them to update schemas/org-env-config-schema.json
      2. Check if secrets should go in {org_id}-{env_type}-config-secrets.json
      3. Verify new keys follow kebab-case naming convention
      4. Suggest appropriate section (global, script-behavior, environments)
    </instruction>
    
    <instruction priority="high">
      Challenge vague requirements:
      - "Process data" ‚Üí What specific transformations?
      - "Call API" ‚Üí Which endpoints? What data?
      - "Generate report" ‚Üí What format? What metrics?
      - "Save file" ‚Üí JSON? Excel? CSV? What structure?
    </instruction>
    
    <instruction priority="high">
      NEVER use print(), always use logger
      NEVER construct paths manually, use get_path()
      NEVER pass individual params, pass config dict
      ALWAYS include type hints and docstrings
      ALWAYS use HelpfulError for user-facing errors
      NEVER log sensitive data directly (tokens are auto-redacted but don't test it)
    </instruction>
  </ai_behavior>

  <critical_patterns>
    <pattern name="script_structure">
      # src/script_name.py  ‚Üê Path comment ALWAYS first line
      """Docstring with purpose and usage."""
      
      from typing import Dict, Any  # Type hints always
      from datetime import datetime, timezone
      
      from utils.logger import setup_logger
      from utils.script_runner import parse_args_and_load_config
      from utils.load_n_save import TxoDataHandler
      from utils.exceptions import HelpfulError
      
      logger = setup_logger()  # Logger before any code
      data_handler = TxoDataHandler()
      
      def main():
          config = parse_args_and_load_config("Description")
          # config automatically has: _org_id, _env_type, _token
    </pattern>
    
    <pattern name="error_handling">
      Use HelpfulError for clear user guidance:
      
      raise HelpfulError(
          what_went_wrong="Configuration file 'x.json' not found",
          how_to_fix="Create the file in config/ directory",
          example="See config/example.json for format"
      )
      
      Output shows:
      ‚ùå Problem: Configuration file 'x.json' not found
      ‚úÖ Solution: Create the file in config/ directory
      üìù Example: See config/example.json for format
    </pattern>
    
    <pattern name="config_access">
      # Required config - will raise KeyError if missing
      api_url = config['global']['api-base-url']  # Hard fail
      
      # Optional config - returns None if missing  
      timeout = config.get('script-behavior', {}).get('api-timeouts', {}).get('rest-timeout-seconds', 60)
    </pattern>
    
    <pattern name="output_naming">
      Always include org_id, env_type, and UTC timestamp:
      
      utc = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H%MZ")
      filename = f"{config['_org_id']}-{config['_env_type']}-report_{utc}.xlsx"
      # Creates: txo-prod-report_2025-01-15T1430Z.xlsx
    </pattern>
  </critical_patterns>

  <configuration_structure>
    <required_sections>
      Config file: config/{org_id}-{env_type}-config.json
      Secrets file: config/{org_id}-{env_type}-config-secrets.json (gitignored)
    </required_sections>
    
    <main_config>
      {
        "global": {
          "api-base-url": "https://api.example.com",  # REQUIRED
          "api-version": "v2",                         # REQUIRED (format: v1, v2.1)
          "tenant-id": "azure-tenant-guid",            # For OAuth
          "client-id": "oauth-client-id",              # For OAuth
          "oauth-scope": "https://api/.default"        # For OAuth
        },
        "script-behavior": {
          "enable-rate-limiting": true,                # Prevent API bans
          "rate-limit-per-second": 10,                 # Max calls/second
          "enable-circuit-breaker": true,              # Prevent cascade failures
          "circuit-breaker-threshold": 5,              # Failures before open
          "circuit-breaker-timeout": 60,               # Seconds before retry
          "api-timeouts": {
            "rest-timeout-seconds": 60,                # REST timeout
            "max-retries": 3,                          # Retry attempts
            "backoff-factor": 2.0,                     # Exponential backoff
            "async-max-wait": 300,                     # Max wait for 202 responses
            "async-poll-interval": 5                   # Polling interval for async
          },
          "jitter": {
            "min-factor": 0.8,                         # Jitter minimum
            "max-factor": 1.2                          # Jitter maximum
          },
          "api-delay-seconds": 1,                      # Delay between calls
          "batch-sizes": {
            "read-batch-size": 100,                    # For pagination
            "write-batch-size": 50                     # For bulk operations
          }
        },
        "environments": {                              # Optional env-specific config
          "test": {
            "api-endpoint": "https://test-api.example.com"
          },
          "prod": {
            "api-endpoint": "https://api.example.com"
          }
        }
      }
    </main_config>
    
    <secrets_config>
      # NEVER commit this file - it's gitignored
      {
        "client-secret": "oauth-client-secret",        # OAuth secret
        "az-token": "Bearer eyJ...",                   # Fallback token
        "api-key": "optional-api-key"                  # Additional API keys
      }
    </secrets_config>
    
    <adding_custom_config>
      # When adding new configuration:
      1. Add to appropriate section (global, script-behavior, or create new)
      2. Use kebab-case for keys: "my-custom-value"
      3. Update schemas/org-env-config-schema.json immediately
      4. Document purpose in schema description
      5. Set reasonable defaults in schema
      
      # Example custom section:
      "my-feature": {
        "enabled": true,
        "custom-endpoint": "https://my-api.com",
        "retry-count": 3
      }
    </adding_custom_config>
  </configuration_structure>

  <intelligent_save_pattern>
    <description>
      TxoDataHandler.save() automatically detects data type and saves appropriately.
      No need for save_json(), save_excel() - just use save() with correct extension!
    </description>
    
    <automatic_detection>
      # DataFrame + .csv ‚Üí saves as CSV
      data_handler.save(df, "output", "data.csv", index=False)
      
      # DataFrame + .xlsx ‚Üí saves as Excel
      data_handler.save(df, "output", "data.xlsx", index=False, sheet_name="Results")
      
      # dict/list ‚Üí saves as JSON (handles Decimal automatically!)
      data_handler.save({"amount": Decimal("99.99")}, "output", "data.json", indent=2)
      
      # string ‚Üí saves as text file
      data_handler.save("Report text", "output", "report.txt")
      
      # Workbook object ‚Üí calls its save method
      data_handler.save(workbook, "output", "workbook.xlsx")
    </automatic_detection>
    
    <common_mistakes>
      # WRONG: Trying to save DataFrame as JSON directly
      data_handler.save(df, "output", "data.json")  # Will fail!
      
      # RIGHT: Convert DataFrame first
      data_handler.save(df.to_dict('records'), "output", "data.json")
      
      # WRONG: Using non-existent methods
      data_handler.save_json(data, "output", "file.json")  # No such method!
      
      # RIGHT: Just use save()
      data_handler.save(data, "output", "file.json")
    </common_mistakes>
  </intelligent_save_pattern>

  <v2_features>
    <security>
      <token_redaction>
        Logger automatically redacts sensitive data:
        - Bearer tokens ‚Üí [REDACTED]
        - JWT tokens ‚Üí [REDACTED_JWT]
        - Passwords ‚Üí [REDACTED]
        - API keys (40+ chars) ‚Üí [REDACTED_TOKEN]
        
        Still, NEVER intentionally log tokens/secrets!
      </token_redaction>
      
      <secrets_separation>
        Public config: {org_id}-{env_type}-config.json (can commit)
        Secrets: {org_id}-{env_type}-config-secrets.json (gitignored)
      </secrets_separation>
    </security>
    
    <resilience>
      <rate_limiting>
        # Enable in config
        "enable-rate-limiting": true
        "rate-limit-per-second": 10
        
        # Automatically applied to API calls
        api = create_rest_api(config)  # Has rate limiting
      </rate_limiting>
      
      <circuit_breaker>
        # Enable in config
        "enable-circuit-breaker": true
        "circuit-breaker-threshold": 5
        "circuit-breaker-timeout": 60
        
        # Prevents cascade failures automatically
      </circuit_breaker>
      
      <async_operations>
        # 202 Accepted handled automatically!
        result = api.post("/long-operation", data)
        # Polls Location header until complete
        # Respects Retry-After header
        # Times out after async-max-wait (default 300s)
      </async_operations>
    </resilience>
    
    <helpful_errors>
      ALWAYS use HelpfulError for user-facing errors:
      - Provides clear problem description
      - Gives actionable solution
      - Shows example when helpful
      - No confusing stack traces for users
    </helpful_errors>
    
    <resource_management>
      # Use context managers for cleanup
      with ApiManager(config) as manager:
          api = manager.get_rest_api()
          # Automatic cleanup on exit
      
      # Or with API directly
      with create_rest_api(config) as api:
          data = api.get("/endpoint")
    </resource_management>
  </v2_features>

  <helper_modules>
    <module name="utils.script_runner">
      <function>
        parse_args_and_load_config(description: str) ‚Üí Dict
        ‚Üí Returns config with _org_id, _env_type, _token injected
        ‚Üí Validates config against schema
        ‚Üí Handles all initialization
      </function>
    </module>

    <module name="utils.logger">
      <function>
        setup_logger(org_id=None) ‚Üí TxoLogger
        ‚Üí Logs INFO to console, DEBUG to file
        ‚Üí Automatically redacts tokens/secrets
        ‚Üí Thread-safe singleton
      </function>
    </module>

    <module name="utils.load_n_save">
      <class name="TxoDataHandler">
        <method>load_json(directory, filename) ‚Üí Dict/List</method>
        <method>load_excel(directory, filename, sheet_name=0) ‚Üí DataFrame</method>
        <method>load_csv(directory, filename) ‚Üí DataFrame</method>
        <method>
          save(data, directory, filename, **kwargs) ‚Üí Path
          INTELLIGENT TYPE DETECTION:
          - DataFrame ‚Üí CSV/Excel based on extension
          - dict/list ‚Üí JSON with Decimal support
          - string ‚Üí text file
          - Workbook ‚Üí Excel via object's save()
        </method>
        <method>save_gzip(data, directory, filename) ‚Üí Path</method>
        <method>exists(directory, filename) ‚Üí bool</method>
        <method>delete(directory, filename) ‚Üí bool</method>
      </class>
    </module>

    <module name="utils.api_factory">
      <function>
        create_rest_api(config) ‚Üí TxoRestAPI
        ‚Üí Includes retry, rate limiting, circuit breaker
        ‚Üí Handles 202 Accepted automatically
        ‚Üí Session pooling (max 50)
      </function>
      <class name="ApiManager">
        Context manager for API lifecycle
      </class>
    </module>

    <module name="utils.exceptions">
      <class>HelpfulError(what_went_wrong, how_to_fix, example=None)</class>
      <class>ApiOperationError</class>
      <class>ApiTimeoutError</class>
      <class>ApiAuthenticationError</class>
      <class>ApiRateLimitError (has retry_after attribute)</class>
      <class>ConfigurationError</class>
      <class>ValidationError</class>
      <class>FileOperationError</class>
    </module>

    <module name="utils.api_common">
      <class>RateLimiter(calls_per_second=10)</class>
      <class>CircuitBreaker(failure_threshold=5, timeout=60)</class>
      <function>apply_jitter(delay, config) ‚Üí float</function>
      <function>manual_retry(func, max_retries=3, backoff=2.0)</function>
    </module>

    <module name="utils.path_helpers">
      <function>
        get_path(category, filename) ‚Üí Path
        Categories: 'config', 'data', 'output', 'logs', 'tmp'
      </function>
    </module>
  </helper_modules>

  <common_patterns>
    <save_patterns>
      # API response to JSON
      api_response = {"status": "ok", "count": 100}
      path = data_handler.save(api_response, "output", 
                              f"{config['_org_id']}-{config['_env_type']}-response_{utc}.json")
      
      # DataFrame to CSV
      df = pd.DataFrame(results)
      path = data_handler.save(df, "output",
                              f"{config['_org_id']}-{config['_env_type']}-data_{utc}.csv",
                              index=False)
      
      # DataFrame to Excel
      path = data_handler.save(df, "output",
                              f"{config['_org_id']}-{config['_env_type']}-report_{utc}.xlsx",
                              index=False, sheet_name="Results")
      
      # Error report as text
      error_text = "\n".join(errors)
      path = data_handler.save(error_text, "output",
                              f"{config['_org_id']}-{config['_env_type']}-errors_{utc}.txt")
    </save_patterns>
    
    <error_patterns>
      # Check file exists
      if not data_handler.exists("config", config_file):
          raise HelpfulError(
              what_went_wrong=f"Config file '{config_file}' not found",
              how_to_fix=f"Create config/{config_file}",
              example="Copy config/example.json as template"
          )
      
      # Validate required config
      if 'api-base-url' not in config.get('global', {}):
          raise HelpfulError(
              what_went_wrong="Missing 'api-base-url' in config",
              how_to_fix="Add to 'global' section",
              example='{"global": {"api-base-url": "https://api.example.com"}}'
          )
      
      # Handle API errors
      try:
          result = api.get(url)
      except ApiRateLimitError as e:
          if e.retry_after:
              logger.warning(f"Rate limited, waiting {e.retry_after}s")
              time.sleep(e.retry_after)
      except ApiAuthenticationError:
          raise HelpfulError(
              what_went_wrong="Authentication failed",
              how_to_fix="Check your token/credentials",
              example="Ensure client-secret is in secrets file"
          )
    </error_patterns>
  </common_patterns>

  <best_practices>
    <rule>Every function needs type hints and docstring</rule>
    <rule>Use logger for all output, never print()</rule>
    <rule>Handle errors with try/except and specific exceptions</rule>
    <rule>Validate config keys exist before accessing</rule>
    <rule>Use HelpfulError for user-facing errors</rule>
    <rule>Pass entire config dict to functions</rule>
    <rule>Use path_helpers for all file paths</rule>
    <rule>Include UTC timestamp in output filenames</rule>
    <rule>Update JSON schema when adding config keys</rule>
    <rule>Put secrets in separate gitignored file</rule>
    <rule>Use context managers for resource cleanup</rule>
    <rule>Let data_handler.save() detect type automatically</rule>
  </best_practices>

  <debugging_helpers>
    <log_levels>
      logger.debug()  # Detailed info, only in file
      logger.info()   # Important milestones, console + file
      logger.warning() # Potential issues
      logger.error()  # Errors occurred
      logger.critical() # System failures
    </log_levels>
    
    <debug_tips>
      # Log actual values being used
      logger.debug(f"Config keys: {list(config.keys())}")
      logger.debug(f"API URL: {url}")
      logger.debug(f"Response status: {response.status_code}")
      
      # Log data transformations
      logger.debug(f"Input: {len(input_data)} records")
      logger.debug(f"After filter: {len(filtered_data)} records")
      
      # Check file operations
      logger.debug(f"Saving to: {output_path}")
      logger.debug(f"File size: {data_handler.get_size('output', filename):,} bytes")
    </debug_tips>
  </debugging_helpers>

  <reminder_triggers>
    <on_config_change>
      If user modifies configuration structure in conversation:
      "üìå Reminder: Since you're changing the config structure, don't forget to:
      1. Update schemas/org-env-config-schema.json
      2. Put any secrets in {org_id}-{env_type}-config-secrets.json
      3. Use kebab-case for new keys"
    </on_config_change>
    
    <on_save_confusion>
      If user tries save_json() or asks about save methods:
      "üí° Note: Just use data_handler.save() - it automatically detects the type!
      - .json extension ‚Üí saves as JSON
      - .csv extension ‚Üí saves as CSV
      - .xlsx extension ‚Üí saves as Excel
      The method figures it out from your data and extension."
    </on_save_confusion>
    
    <on_missing_timestamp>
      If output filename doesn't include timestamp:
      "‚ö†Ô∏è Don't forget the UTC timestamp in output filenames:
      utc = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H%MZ')
      filename = f'{org_id}-{env_type}-output_{utc}.json'"
    </on_missing_timestamp>
  </reminder_triggers>
</txo_python_template>